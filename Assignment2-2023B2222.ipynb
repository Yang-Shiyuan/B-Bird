{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**Kaggle Team Name:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Assignment 2 - Game Music Tagging\n",
    "Due date: see Assignment 2 on Canvas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this assignment, we intend do classify the category of birds according to its one audio clip.\n",
    "\n",
    "\n",
    "## Steps\n",
    "### 1. Converting the raw audio format to Mel-spec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:04.364095Z",
     "start_time": "2023-02-16T14:36:03.731045Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "random.seed(100)\n",
    "import csv\n",
    "from scipy import io\n",
    "import pickle\n",
    "from IPython.display import Audio, display\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:04.367896Z",
     "start_time": "2023-02-16T14:36:04.365753Z"
    }
   },
   "outputs": [],
   "source": [
    "def showAudio(info):\n",
    "    myfile = 'musicmp3/' + info['fname'] + '.mp3'\n",
    "    if os.path.exists(myfile):\n",
    "        display(Audio(myfile))\n",
    "    else:\n",
    "        print(\"*** mp3 file \" + myfile + \" could not be found ***\")\n",
    "\n",
    "def load_pickle(fname):\n",
    "    f = open(fname, 'rb')\n",
    "    out = pickle.load(f)\n",
    "    f.close()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "The training and test data are stored in various pickle files. Here we assume the data is stored in the `musicdata` directory. The below code will load the data, including tags and extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:04.638669Z",
     "start_time": "2023-02-16T14:36:04.377568Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_tags  = load_pickle('musicdata/train_tags.pickle3')\n",
    "# train_mfccs = load_pickle('musicdata/train_mfccs.pickle3')\n",
    "# train_mels  = load_pickle('musicdata/train_mels.pickle3')\n",
    "# train_info  = load_pickle('musicdata/train_info.pickle3') # useless\n",
    "\n",
    "# test_mfccs = load_pickle('musicdata/test_mfccs.pickle3')\n",
    "# test_mels  = load_pickle('musicdata/test_mels.pickle3')\n",
    "# test_info  = load_pickle('musicdata/test_info.pickle3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read the data\n",
    "# data_file = load_pickle('/mnt/lyh/Code/temple.pickle3')\n",
    "data_file = load_pickle('train_mel(dB,sr=32k,bin=128).pickle3')\n",
    "mel = data_file['mel']\n",
    "label = data_file['primary_label']\n",
    "# convert each element in list to sub-list\n",
    "label = [i.split(',') for i in label]\n",
    "\n",
    "# 2. split the data into train and test\n",
    "train_mels, test_mels, train_mel_tags, test_mel_tags = model_selection.train_test_split(mel, label, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_outlier(label, train_mels, test_mels, train_mel_tags, test_mel_tags):\n",
    "\n",
    "    coun = pd.value_counts(label)\n",
    "\n",
    "    count_lis = dict(zip(coun.index.values.tolist(),coun.values.tolist()))\n",
    "\n",
    "    for key in count_lis:\n",
    "        if key.split(',') not in train_mel_tags:\n",
    "            print('yes-----------', key)\n",
    "            index_outlier_in_test = test_mel_tags.index(key.split(','))\n",
    "            print('before removing the outlier, the len of training and test data is: ', len(train_mel_tags),  len(test_mel_tags))\n",
    "            value = test_mels.pop(index_outlier_in_test)\n",
    "            class_name = test_mel_tags.pop(index_outlier_in_test)\n",
    "            \n",
    "            # append the value and class to train data\n",
    "            train_mel_tags.append(class_name)\n",
    "            train_mels.append(value)\n",
    "            print('After removing the outlier, the len of training and test data is: ', len(train_mel_tags), len(test_mel_tags))\n",
    "\n",
    "process_outlier(data_file['primary_label'], train_mels,test_mels, train_mel_tags, test_mel_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mfccs\n",
    "mfccs = load_pickle('mfccs(n=20).pickle3')\n",
    "\n",
    "train_mfccs, test_mfccs, train_mfcc_tags, test_mfcc_tags = model_selection.train_test_split(mfccs, label, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "process_outlier(data_file['primary_label'], train_mfccs, test_mfccs, train_mfcc_tags, test_mfcc_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the things in the dataset:\n",
    "\n",
    "- `train_info` - info about each sound in the training set.\n",
    "- `train_mels` - the Mel-frequency spectrogram for each sound in the training set. Mel-frequency is a logarithmically-transformed frequency with better perceptual distance.  More details [here](https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8).\n",
    "- `train_mfccs` -  MFCCs (Mel-frequency cepstrum coefficients) are dimensionality-reduced version of the Mel-frequency spectrogram. Specifically, the log is applied to the magnitudes, and then a Discrete Cosine Transform is applied at each time. \n",
    "- `train_tags` - the descriptive tags for each sound in the training set.\n",
    "- `test_info` - info about each sound in the test set.\n",
    "- `test_mels` - the Mel Spectrogram for each sound in the test.\n",
    "- `test_mfccs` - the MFCC features for each sound in the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the one song in the training set, as well as the tags and other info. To play the audio, we assume the mp3s are available in the `musicmp3` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:05.372005Z",
     "start_time": "2023-02-16T14:36:05.306053Z"
    }
   },
   "outputs": [],
   "source": [
    "# ii = 9\n",
    "# print(len(train_mfcc_tags))\n",
    "# # showAudio(train_info[ii])\n",
    "# print(train_mfcc_tags[ii])\n",
    "# print(train_info[ii])\n",
    "\n",
    "# print(train_mfccs[ii].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Mel-frequency spectrogram, which shows the frequency content over time. The spectrogram is stored in an `B x T` matrix, where `B` is the number of bins, and `T` is the temporal length.  The left plot shows the original Mel spectrogram (with time increasing to the right).  The right plot shows the log magnitude, which can better visualize the differences.  Here we use `B=128` Mel-bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:12.869695Z",
     "start_time": "2023-02-16T14:36:12.657948Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_mels[ii].shape)\n",
    "\n",
    "plt.figure(figsize=(17,8))\n",
    "plt.imshow(train_mels[ii]);\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('mel bin');\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs are a dimensionality-reduced version of the Mel-spectrogram.  To get the MFCC, the Discrete Cosine Transform (DCT) is applied to each 128-dim log-Mel bin vector.  Here we use 20-dimension DCT, so the 128-dim vector is convereted to 20-dim in each time step.  The left plot shows the MFCCs as an image, while the right plots the individual dimensions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:14.432490Z",
     "start_time": "2023-02-16T14:36:14.284684Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# test_mfccs = mel_2_mfcc(test_mels)\n",
    "# train_mfccs = mel_2_mfcc(train_mels)\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_mels[ii]);\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('mfcc bin')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_mfccs[ii])\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('mfcc value')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing - Delta MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you might notice is that the MFCC vectors are time-series.  One trick to include time-series information into a vector representation is to append the difference between two consecutive feature vectors.  This way, we can include some relationship between two time steps in the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:16.038557Z",
     "start_time": "2023-02-16T14:36:16.032591Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute delta MFCCs\n",
    "def compute_delta_mfccs(mfccs):\n",
    "    dmfccs = []\n",
    "    for m in mfccs:\n",
    "        tmp = m[1:] - m[0:-1]\n",
    "        dm = hstack((m[0:-1], tmp))\n",
    "        dmfccs.append(dm)\n",
    "    return dmfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:16.643528Z",
     "start_time": "2023-02-16T14:36:16.532495Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dmfccs = compute_delta_mfccs(train_mfccs)\n",
    "test_dmfccs  = compute_delta_mfccs(test_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:16.977152Z",
     "start_time": "2023-02-16T14:36:16.952139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_dmfccs[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing - bag-of-words\n",
    "\n",
    "The next problem you might notice is that the number of MFCCs is different for each sound, since sound can have different lengths.  Hence, before using our machine learning algorithms, we need to encode the MFCCs into a vector.\n",
    "\n",
    "One solution is to use a \"bag-of-audio-words\" representation, which is analogous to the bag-of-words representation for text.\n",
    "Here, we build a vocabulary of \"audio-words\" and map each MFCC to one of the words.  Then we can represent each sound as a histogram of counts.\n",
    "\n",
    "We will use the k-means clustering algorithm to build the codebook of audio words.  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:17.943037Z",
     "start_time": "2023-02-16T14:36:17.868627Z"
    }
   },
   "outputs": [],
   "source": [
    "# put dmfccs from all training data together\n",
    "all_dmfccs = vstack(train_dmfccs)\n",
    "print(all_dmfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:49.486397Z",
     "start_time": "2023-02-16T14:36:21.242777Z"
    }
   },
   "outputs": [],
   "source": [
    "# run k-means to build codebook\n",
    "km = cluster.KMeans(n_clusters=100, random_state=4487)\n",
    "km.fit(all_dmfccs[0::100])  # subsample by 10 to make it faster\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the data into BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:49.495871Z",
     "start_time": "2023-02-16T14:36:49.490866Z"
    }
   },
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.cluster_centers_.shape[0]\n",
    "    bows = zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.857715Z",
     "start_time": "2023-02-16T14:36:49.498217Z"
    }
   },
   "outputs": [],
   "source": [
    "train_bow = bow_transform(km, train_dmfccs)\n",
    "test_bow  = bow_transform(km, test_dmfccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag pre-processing\n",
    "\n",
    "Next, we extract all the tags from the data, and get a unique list of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.862395Z",
     "start_time": "2023-02-16T14:36:59.859437Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class_names = load_pickle('bird_names.pickle3')\n",
    "class_names = [i.split(',') for i in class_names]\n",
    "\n",
    "tagnames, tagnames_counts = unique(concatenate(class_names), return_counts=True)\n",
    "for a,b in zip(tagnames, tagnames_counts):\n",
    "    print(\"{}: {}\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the list of tags for each sound into binary attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.865262Z",
     "start_time": "2023-02-16T14:36:59.863310Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert list of tags into binary class labels\n",
    "def tags2class(tags, tagnames):\n",
    "    b = zeros(shape=(len(tags), len(tagnames)))\n",
    "    for i,t in enumerate(tags):\n",
    "        for j,n in enumerate(tagnames):\n",
    "            if n in t:\n",
    "                b[i,j] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.869811Z",
     "start_time": "2023-02-16T14:36:59.865860Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_classes[i,j] = absence/presence of the j-th tag in the i-th sound\n",
    "train_classes = tags2class(train_mfcc_tags, tagnames)\n",
    "\n",
    "# for test data, as there are some items doesnot appear in test set\n",
    "test_tagnames, _ = unique(concatenate(test_mfcc_tags), return_counts=True)\n",
    "test_classes = tags2class(test_mfcc_tags, test_tagnames)\n",
    "print(train_classes.shape, test_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.873279Z",
     "start_time": "2023-02-16T14:36:59.870816Z"
    }
   },
   "outputs": [],
   "source": [
    "# double check we did this correctly...\n",
    "# it should be the same as the tag counts above\n",
    "sum(train_classes,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_classes = zeros(shape=(len(test_mfcc_tags), len(tagnames)))\n",
    "# for i,t in enumerate(test_mfcc_tags):\n",
    "#     for j,n in enumerate(tagnames):\n",
    "#         if n in t:\n",
    "#             test_classes[i,j] = 1\n",
    "            \n",
    "print(test_classes[1])#.sum()\n",
    "for i in range(test_classes.shape[0]):\n",
    "    if test_classes[i].sum() != 1:\n",
    "        print(test_classes[i].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline experiments\n",
    "\n",
    "Next, we will run a baseline experiment doing semantic tagging with bag-of-audio words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TF-IDF to the count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:36:59.880054Z",
     "start_time": "2023-02-16T14:36:59.874295Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "train_Xtf = tf_trans.fit_transform(train_bow)\n",
    "test_Xtf  = tf_trans.transform(test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn a logisic regression classifier for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.389378Z",
     "start_time": "2023-02-16T14:36:59.880922Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tagmodels = {}\n",
    "\n",
    "for i,t in enumerate(tagnames):\n",
    "    print('training {} - {}'.format(i, t))\n",
    "    myY = train_classes[:,i].ravel()\n",
    "    lr = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,10), cv=5, class_weight='balanced', solver='saga', n_jobs=8)\n",
    "\n",
    "    lr.fit(train_Xtf, myY)\n",
    "\n",
    "    tagmodels[t] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how we did on tagging the training set, we compute the tag scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.454445Z",
     "start_time": "2023-02-16T14:37:04.430871Z"
    }
   },
   "outputs": [],
   "source": [
    "train_predscore = zeros(shape=(len(train_mfccs), len(tagnames)))\n",
    "\n",
    "for i,t in enumerate(tagnames):\n",
    "    tmp = tagmodels[t].decision_function(train_Xtf)\n",
    "    train_predscore[:,i] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot the ROC curve using the training classes and training predicted scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.463173Z",
     "start_time": "2023-02-16T14:37:04.457873Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot an ROC curve using class labels and class scores\n",
    "import numpy as np\n",
    "\n",
    "def plot_roc(tagnames, Yclasses, Yscores):\n",
    "    fprall = []\n",
    "    tprall = []\n",
    "    aucall = []\n",
    "    for i in range(len(tagnames)):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Yclasses[:,i], Yscores[:,i])\n",
    "\n",
    "        plt.plot(fpr, tpr, lw=0.5, alpha=0.5)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        tprall.append(tpr)        \n",
    "        fprall.append(fpr)\n",
    "        aucall.append(auc)\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    all_fpr = unique(concatenate(fprall))\n",
    "    mean_tpr = zeros_like(all_fpr)\n",
    "    \n",
    "    for i in range(len(tagnames)):\n",
    "        mean_tpr += interp(all_fpr, fprall[i], tprall[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(tagnames)\n",
    "\n",
    "    # auc of the average ROC curve\n",
    "    auc = metrics.auc(all_fpr, mean_tpr)\n",
    "\n",
    "    # average AUC\n",
    "    mc_auc = mean(aucall)\n",
    "\n",
    "    plt.plot(all_fpr, mean_tpr, 'k-', lw=2)\n",
    "    plt.title('MCAUC={:.4f}, AUC={:.4f}'.format(mc_auc, auc))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.555206Z",
     "start_time": "2023-02-16T14:37:04.466691Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_roc(tagnames, train_classes, train_predscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that AUC is the AUC of the black curve, while MCAUC is the average of the AUCs for all the color curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the LR classifiers to the test set to predict the score for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.577984Z",
     "start_time": "2023-02-16T14:37:04.563800Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predscore = zeros(shape=(len(test_mfccs), len(tagnames)))\n",
    "\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('predicting {} - {}'.format(i, t))\n",
    "    # try:\n",
    "    tmp = tagmodels[t].decision_function(test_Xtf)\n",
    "    # except:\n",
    "    #     print('ignoring the outlier')\n",
    "    test_predscore[:,i] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the scores, now lets look at the predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.586406Z",
     "start_time": "2023-02-16T14:37:04.583200Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert binary class vector into a list of tags\n",
    "def class2tags(classes, tagnames):\n",
    "    tags = []\n",
    "    for n in range(classes.shape[0]):\n",
    "        tmp = []\n",
    "        for i in range(classes.shape[1]):\n",
    "            if classes[n,i]:\n",
    "                tmp.append(tagnames[i])\n",
    "        tags.append(\" \".join(tmp))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the score into a binary class label using a threshold (usually 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.595834Z",
     "start_time": "2023-02-16T14:37:04.592097Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert score into binary class 0 or 1.  \n",
    "test_predclass = test_predscore>0\n",
    "\n",
    "# convert to tags\n",
    "test_predtags = class2tags(test_predclass, tagnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write the tag scores for the test set for submission to Kaggle. We need to upload the tag scores so that Kaggle can generate the ROC curves and calculate AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.713447Z",
     "start_time": "2023-02-16T14:37:04.708712Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_csv_kaggle_tags(fname, tagnames, Yscores):\n",
    "    # header\n",
    "    tmp = [['Id']]\n",
    "    for t in tagnames:\n",
    "        tmp[0].append(t)    \n",
    "    \n",
    "    # add ID numbers for each Y, and usage if necessary\n",
    "    for i in range(len(Yscores)):\n",
    "        tmp2 = [(i+1)]\n",
    "        for t in range(len(tagnames)):\n",
    "            tmp2.append(Yscores[i,t])\n",
    "        \n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    f = open(fname, 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T14:37:04.722054Z",
     "start_time": "2023-02-16T14:37:04.716278Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(test_predscore.shape)\n",
    "# write_csv_kaggle_tags(\"music_bow_baseline.csv\", tagnames, test_predscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## YOUR CODE and DOCUMENTATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Feature Representations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Dimensionality Reduction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, testX, trainY, testY = train_test_split(train_bow, train_classes, test_size=0.2)\n",
    "trainX, trainY = train_bow, train_classes\n",
    "testX, testY = test_bow, test_classes\n",
    "\n",
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "train_Xtf = tf_trans.fit_transform(trainX)\n",
    "test_Xtf  = tf_trans.transform(testX)\n",
    "\n",
    "print(train_Xtf.shape, test_Xtf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tagmodels(tagmodels, train_x=train_Xtf, test_x=test_Xtf):\n",
    "    # evaluate on the train set\n",
    "    train_predscore = zeros(shape=trainY.shape)\n",
    "    for i,t in enumerate(tagnames):\n",
    "        # print('predicting {} - {}'.format(i, t))\n",
    "        tmp = tagmodels[t].decision_function(train_x)\n",
    "        train_predscore[:,i] = tmp\n",
    "    \n",
    "    # test set\n",
    "    test_predscore = zeros(shape=testY.shape)\n",
    "    for i,t in enumerate(test_tagnames):\n",
    "        # print('predicting {} - {}'.format(i, t))\n",
    "        tmp = tagmodels[t].decision_function(test_x)\n",
    "        test_predscore[:,i] = tmp\n",
    "\n",
    "    ROC_train = metrics.roc_auc_score(trainY, train_predscore, average=None).mean()\n",
    "    ROC_test = metrics.roc_auc_score(testY, test_predscore, average=None).mean()\n",
    "    # print(type(testY), type(test_predscore))\n",
    "    # ROC_test = metrics.label_ranking_average_precision_score(testY, test_predscore)\n",
    "    \n",
    "    print(f'train: {ROC_train}, test: {ROC_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('----- Logistic Regression ------')\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,10), cv=5, class_weight='balanced', solver='saga', n_jobs=8)\n",
    "    lr.fit(train_Xtf, myY)\n",
    "    tagmodels[t] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation for logistic regression\n",
    "# print(train_Xtf.shape, testY.shape, test_predscore.shape, test_Xtf.shape)\n",
    "evaluate_tagmodels(tagmodels, train_Xtf, test_Xtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n----- Logistic Regression with PCA ------')\n",
    "\n",
    "pca = decomposition.PCA(n_components=20) \n",
    "WtrainX  = pca.fit_transform(trainX)  \n",
    "WtestX = pca.transform(testX)  \n",
    "print(WtrainX.shape, WtestX.shape)\n",
    "\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,10), cv=5, class_weight='balanced', solver='saga', max_iter=2000, n_jobs=8)\n",
    "    lr.fit(WtrainX, myY)\n",
    "    tagmodels[t] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation for logistic regression (with PCA)\n",
    "evaluate_tagmodels(tagmodels, WtrainX, WtestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n------- Linear Dimensionality Reduction - NMF ----------')\n",
    "\n",
    "nmf = decomposition.NMF(n_components=20)\n",
    "WtrainX_nmf  = nmf.fit_transform(trainX)  \n",
    "WtestX_nmf = nmf.transform(testX)  \n",
    "\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,10), cv=5, class_weight='balanced', solver='saga', max_iter=2000, n_jobs=8)\n",
    "    lr.fit(WtrainX_nmf, myY)\n",
    "    tagmodels[t] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation (Linear Dimensionality Reduction - NMF)\n",
    "evaluate_tagmodels(tagmodels, WtrainX_nmf, WtestX_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------- Non-Linear Dimensionality Reduction - KPCA ----------')\n",
    "\n",
    "kpca = decomposition.KernelPCA(n_components=20, kernel='rbf', gamma=0.001, n_jobs=-1)\n",
    "WtrainX_kpca  = kpca.fit_transform(trainX)  \n",
    "WtestX_kpca = kpca.transform(testX)  \n",
    "\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = linear_model.LogisticRegressionCV(Cs=logspace(-4,4,10), cv=5, class_weight='balanced', solver='saga', max_iter=2000, n_jobs=8)\n",
    "    lr.fit(WtrainX_kpca, myY)\n",
    "    tagmodels[t] = lr\n",
    "\n",
    "# test_predscore = zeros(shape=testY.shape)\n",
    "# for i,t in enumerate(tagnames):\n",
    "#     # print('predicting {} - {}'.format(i, t))\n",
    "#     tmp = tagmodels[t].decision_function(WtestX_kpca)\n",
    "#     test_predscore[:,i] = tmp\n",
    "# ROC_test = metrics.roc_auc_score(testY, test_predscore, average=None).mean()\n",
    "# print(f'test: {ROC_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation (KPCA)\n",
    "evaluate_tagmodels(tagmodels, WtrainX_kpca, WtestX_kpca)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Image Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----- Linear SVM ------')\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = svm.SVC(kernel='linear')\n",
    "    lr.fit(train_Xtf, myY)\n",
    "    tagmodels[t] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tagmodels(tagmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----- SVM with RBF kernel ------')\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    lr = svm.SVC(kernel='rbf')\n",
    "    lr.fit(train_Xtf, myY)\n",
    "    tagmodels[t] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_tagmodels(tagmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----- SVM with RBF kernel (Grid Search) ------')\n",
    "C_tmp = logspace(-2, 3, 10)\n",
    "\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    model_svm = svm.SVC(kernel='rbf')\n",
    "    lr = model_selection.GridSearchCV(estimator=model_svm, param_grid={'C': C_tmp}, cv=5, n_jobs=8)\n",
    "    lr.fit(train_Xtf, myY)\n",
    "    # print(lr.best_params_)\n",
    "    tagmodels[t] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tagmodels(tagmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----  AdaBoost (Grid Search) ------')\n",
    "parameters = {'n_estimators': [50, 100, 150], 'learning_rate': [0.1, 1, 10]}\n",
    "\n",
    "tagmodels = {}\n",
    "for i,t in enumerate(tagnames):\n",
    "    # print('training {} - {}'.format(i, t))\n",
    "    myY = trainY[:,i].ravel()\n",
    "    adaclf = ensemble.AdaBoostClassifier(random_state=4487)\n",
    "    lr = model_selection.GridSearchCV(adaclf, parameters, cv=5, n_jobs=8)\n",
    "    lr.fit(train_Xtf, myY)\n",
    "    tagmodels[t] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tagmodels(tagmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----  XGBClassifier ------')\n",
    "!pip install xgboost\n",
    "import xgboost as xgb  \n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 5, 7, 10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 1, 10],\n",
    "    'n_estimators': [50, 100, 150, 200, 300]\n",
    "}\n",
    "\n",
    "xgbclf = xgb.XGBClassifier()\n",
    "xgbclf = model_selection.GridSearchCV(xgbclf, parameters, cv=5, n_jobs=8)\n",
    "xgbclf.fit(train_Xtf, myY)\n",
    "\n",
    "# y_pred_xgbclf = xgbclf.predict_proba(testX)\n",
    "# ROC_test = metrics.roc_auc_score(testY, y_pred_xgbclf, average=None).mean()\n",
    "# print(ROC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tagmodels(tagmodels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-audio-words (BoAW) is a representation that is commonly used for audio classification, but it may not be suitable for use with a CNN-based classifier. BoAW representations are typically sparse and high-dimensional, which can make it difficult to train a CNN model on them.\n",
    "\n",
    "Instead, for a CNN-based classifier, it is more common to use a spectrogram representation of the audio data. The spectrogram represents the frequency content of the audio signal over time, and can be thought of as a two-dimensional image. This representation can be easily fed into a CNN model, which can learn to extract features that are useful for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 24\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, mels, labels=None, transform=None, size=None):\n",
    "        self.mels = mels\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.size = size \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mel = self.mels[idx]\n",
    "        # mel = log(np.abs(mel) + 1e-10)      ####### Note!\n",
    "\n",
    "        image = Image.fromarray(mel, mode='RGB')    \n",
    "        image = self.transform(image)\n",
    "        # image  = image.div_(255)\n",
    "        \n",
    "        mean = image.mean()\n",
    "        std = image.std()\n",
    "        image = (image - mean) / std \n",
    "\n",
    "        if self.size is not None:\n",
    "            image = torch.nn.functional.interpolate(image.unsqueeze(0), self.size).squeeze(0)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            label = torch.from_numpy(label).float()\n",
    "            \n",
    "            return image, label\n",
    "        \n",
    "        return image \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioCNN, self).__init__()\n",
    "                \n",
    "        backbone = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "        feats = list(backbone.children())\n",
    "        self.feats = feats[0]\n",
    "\n",
    "        lastconv_output_channels = 1280 \n",
    "        ## mlp \n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(lastconv_output_channels, lastconv_output_channels//2),\n",
    "                nn.Hardswish(inplace=True),\n",
    "                nn.Linear(lastconv_output_channels//2, num_classes),\n",
    "            )\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #         nn.Conv2d(\n",
    "        #             lastconv_output_channels,\n",
    "        #             num_classes,\n",
    "        #             kernel_size=(1, 1),\n",
    "        #             stride=(1, 1),\n",
    "        #             padding=(0, 0),\n",
    "        #             bias=False),\n",
    "        #         nn.BatchNorm2d(num_classes),\n",
    "        #         nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        #     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feats(x)\n",
    "        out = self.classifier(out)\n",
    "        return out.squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AudioDataset(test_dmfccs, labels=None, transform=transforms_test, size=(1024, 512))\n",
    "# test_dataset = AudioDataset(test_mels, labels=None, transform=transforms_test, size=(1024, 512))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_trained = AudioCNN(num_classes=num_classes).to(device)\n",
    "model_trained.load_state_dict(torch.load(f'weight_best_roc_(log_0.7468).pt'))\n",
    "model_trained.eval()\n",
    "\n",
    "valid_preds = np.zeros((len(test_dataset), num_classes))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_trained(inputs)\n",
    "        # outputs = torch.sigmoid(outputs)\n",
    "        valid_preds[i * batch_size: (i+1) * batch_size] = outputs.cpu().numpy()\n",
    "\n",
    "write_csv_kaggle_tags(\"music_bow_baseline_(log_0.7468).csv\", tagnames, valid_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different hyperparameters:\n",
    "\n",
    "- different image size\n",
    "    -  (1024, 512): 0.7118\n",
    "    -  (1024, 40): 0.6993\n",
    "- no random flip: 0.7247\n",
    "\n",
    "Try different feature representations:\n",
    "\n",
    "- spectrogram -> 0.7247\n",
    "- log(spectrogram) -> 0.7360\n",
    "\n",
    "Applying a log transformation can enhance the dynamic range of the input features, imroving the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "lyh-pytorch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5178de2df4dd59be69476c0e5364eb40faff0b03048e9a10d78a0d421b553d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
